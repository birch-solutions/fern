types:
  ChatRequestPromptTruncation:
    enum:
      - 'OFF'
      - AUTO
      - AUTO_PRESERVE_ORDER
    docs: >
      Defaults to `AUTO` when `connectors` are specified and `OFF` in all other
      cases.


      Dictates how the prompt will be constructed.


      With `prompt_truncation` set to "AUTO", some elements from `chat_history`
      and `documents` will be dropped in an attempt to construct a prompt that
      fits within the model's context length limit. During this process the
      order of the documents and chat history will be changed and ranked by
      relevance.


      With `prompt_truncation` set to "AUTO_PRESERVE_ORDER", some elements from
      `chat_history` and `documents` will be dropped in an attempt to construct
      a prompt that fits within the model's context length limit. During this
      process the order of the documents and chat history will be preserved as
      they are inputted into the API.


      With `prompt_truncation` set to "OFF", no elements will be dropped. If the
      sum of the inputs exceeds the model's context length limit, a
      `TooManyTokens` error will be returned.


      Compatible Deployments: 
       - AUTO: Cohere Platform Only
       - AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments
    source:
      openapi: openapi/cohere.yaml
  ChatRequestSafetyMode:
    enum:
      - CONTEXTUAL
      - STRICT
      - NONE
    docs: >
      Used to select the [safety instruction](/docs/safety-modes) inserted into
      the prompt. Defaults to `CONTEXTUAL`.

      When `NONE` is specified, the safety instruction will be omitted.


      Safety modes are not yet configurable in combination with `tools`,
      `tool_results` and `documents` parameters.


      **Note**: This parameter is only compatible with models [Command R
      08-2024](/docs/command-r#august-2024-release), [Command R+
      08-2024](/docs/command-r-plus#august-2024-release) and newer.


      Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock,
      Private Deployments
    source:
      openapi: openapi/cohere.yaml
imports:
  v1Root: __package__.yml
service:
  auth: false
  base-path: ''
  endpoints:
    chat:
      path: /v1/chat
      method: POST
      auth: true
      docs: >
        Generates a text response to a user message.

        To learn how to use the Chat API and RAG follow our [Text Generation
        guides](https://docs.cohere.com/docs/chat-api).
      display-name: Chat
      request:
        name: ChatRequest
        headers:
          Accepts:
            type: optional<literal<"text/event-stream">>
            name: accepts
            docs: >
              Pass text/event-stream to receive the streamed response as
              server-sent events. The default is `\n` delimited events.
        body:
          properties:
            message:
              type: string
              docs: >
                Text input for the model to respond to.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              audiences:
                - public
            model:
              type: optional<string>
              docs: >
                Defaults to `command-r-plus-08-2024`.


                The name of a compatible [Cohere
                model](https://docs.cohere.com/docs/models) or the ID of a
                [fine-tuned](https://docs.cohere.com/docs/chat-fine-tuning)
                model.


                Compatible Deployments: Cohere Platform, Private Deployments
              audiences:
                - public
            stream:
              type: optional<boolean>
              docs: >
                Defaults to `false`.


                When `true`, the response will be a JSON stream of events. The
                final event will contain the complete response, and will have an
                `event_type` of `"stream-end"`.


                Streaming is beneficial for user interfaces that render the
                contents of the response piece by piece, as it gets generated.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              audiences:
                - public
            preamble:
              type: optional<string>
              docs: >
                When specified, the default Cohere preamble will be replaced
                with the provided one. Preambles are a part of the prompt used
                to adjust the model's overall behavior and conversation style,
                and use the `SYSTEM` role.


                The `SYSTEM` role is also used for the contents of the optional
                `chat_history=` parameter. When used with the `chat_history=`
                parameter it adds content throughout a conversation. Conversely,
                when used with the `preamble=` parameter it adds content at the
                start of the conversation only.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              audiences:
                - public
            chat_history:
              type: optional<list<unknown>>
              docs: >
                A list of previous messages between the user and the model,
                giving the model conversational context for responding to the
                user's `message`.


                Each item represents a single message in the chat history,
                excluding the current user turn. It has two properties: `role`
                and `message`. The `role` identifies the sender (`CHATBOT`,
                `SYSTEM`, or `USER`), while the `message` contains the text
                content.


                The chat_history parameter should not be used for `SYSTEM`
                messages in most cases. Instead, to add a `SYSTEM` role message
                at the beginning of a conversation, the `preamble` parameter
                should be used.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              audiences:
                - public
            conversation_id:
              type: optional<string>
              docs: >
                An alternative to `chat_history`.


                Providing a `conversation_id` creates or resumes a persisted
                conversation with the specified ID. The ID can be any non empty
                string.


                Compatible Deployments: Cohere Platform
              audiences:
                - public
            prompt_truncation:
              type: optional<ChatRequestPromptTruncation>
              docs: >
                Defaults to `AUTO` when `connectors` are specified and `OFF` in
                all other cases.


                Dictates how the prompt will be constructed.


                With `prompt_truncation` set to "AUTO", some elements from
                `chat_history` and `documents` will be dropped in an attempt to
                construct a prompt that fits within the model's context length
                limit. During this process the order of the documents and chat
                history will be changed and ranked by relevance.


                With `prompt_truncation` set to "AUTO_PRESERVE_ORDER", some
                elements from `chat_history` and `documents` will be dropped in
                an attempt to construct a prompt that fits within the model's
                context length limit. During this process the order of the
                documents and chat history will be preserved as they are
                inputted into the API.


                With `prompt_truncation` set to "OFF", no elements will be
                dropped. If the sum of the inputs exceeds the model's context
                length limit, a `TooManyTokens` error will be returned.


                Compatible Deployments: 
                 - AUTO: Cohere Platform Only
                 - AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments
              audiences:
                - public
            force_single_step:
              type: optional<boolean>
              docs: Forces the chat to be single step. Defaults to `false`.
              audiences:
                - public
            safety_mode:
              type: optional<ChatRequestSafetyMode>
              docs: >
                Used to select the [safety instruction](/docs/safety-modes)
                inserted into the prompt. Defaults to `CONTEXTUAL`.

                When `NONE` is specified, the safety instruction will be
                omitted.


                Safety modes are not yet configurable in combination with
                `tools`, `tool_results` and `documents` parameters.


                **Note**: This parameter is only compatible with models [Command
                R 08-2024](/docs/command-r#august-2024-release), [Command R+
                08-2024](/docs/command-r-plus#august-2024-release) and newer.


                Compatible Deployments: Cohere Platform, Azure, AWS
                Sagemaker/Bedrock, Private Deployments
              audiences:
                - public
              availability: pre-release
      response:
        docs: OK
        type: list<string>
      errors:
        - v1Root.BadRequestError
        - v1Root.UnauthorizedError
        - v1Root.ForbiddenError
        - v1Root.NotFoundError
        - v1Root.UnprocessableEntityError
        - v1Root.TooManyRequestsError
        - v1Root.ClientClosedRequestError
        - v1Root.InternalServerError
        - v1Root.NotImplementedError
        - v1Root.ServiceUnavailableError
        - v1Root.GatewayTimeoutError
      examples:
        - request:
            message: message
          response:
            body:
              - string
      audiences:
        - public
  source:
    openapi: openapi/cohere.yaml
